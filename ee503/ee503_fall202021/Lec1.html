<html xmlns:v="urn:schemas-microsoft-com:vml"
xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns:st1="urn:schemas-microsoft-com:office:smarttags"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 10">
<meta name=Originator content="Microsoft Word 10">
<link rel=File-List href="outline_files/filelist.xml">
<title>EE 503 Signal Analysis and Processing</title>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="place"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="City"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="State"/>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>METU-EEE</o:Author>
  <o:LastAuthor>EEE</o:LastAuthor>
  <o:Revision>2</o:Revision>
  <o:TotalTime>23</o:TotalTime>
  <o:Created>2007-09-21T10:56:00Z</o:Created>
  <o:LastSaved>2007-09-21T10:56:00Z</o:LastSaved>
  <o:Pages>1</o:Pages>
  <o:Words>750</o:Words>
  <o:Characters>4278</o:Characters>
  <o:Company>METU-EEE</o:Company>
  <o:Lines>35</o:Lines>
  <o:Paragraphs>10</o:Paragraphs>
  <o:CharactersWithSpaces>5018</o:CharactersWithSpaces>
  <o:Version>10.2625</o:Version>
 </o:DocumentProperties>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:SpellingState>Clean</w:SpellingState>
  <w:GrammarState>Clean</w:GrammarState>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
  </w:Compatibility>
  <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel>
 </w:WordDocument>
</xml><![endif]--><!--[if !mso]><object
 classid="clsid:38481807-CA0E-42D2-BF39-B33AF135CC4D" id=ieooui></object>
<style>
st1\:*{behavior:url(#ieooui) }
</style>
<![endif]-->
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
span.SpellE
	{mso-style-name:"";
	mso-spl-e:yes;}
span.GramE
	{mso-style-name:"";
	mso-gram-e:yes;}
@page Section1
	{size:612.0pt 792.0pt;
	margin:72.0pt 90.0pt 72.0pt 90.0pt;
	mso-header-margin:35.4pt;
	mso-footer-margin:35.4pt;
	mso-paper-source:0;}
div.Section1
	{page:Section1;}
 /* List Definitions */
 @list l0
	{mso-list-id:24134985;
	mso-list-type:hybrid;
	mso-list-template-ids:1418224520 67698703 67698713 67698715 67698703 67698713 67698715 67698703 67698713 67698715;}
@list l0:level1
	{mso-level-tab-stop:36.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;}
@list l0:level2
	{mso-level-number-format:alpha-lower;
	mso-level-tab-stop:72.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;}
@list l0:level3
	{mso-level-number-format:roman-lower;
	mso-level-tab-stop:108.0pt;
	mso-level-number-position:right;
	text-indent:-9.0pt;}
@list l0:level4
	{mso-level-tab-stop:144.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;}
@list l0:level5
	{mso-level-number-format:alpha-lower;
	mso-level-tab-stop:180.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;}
ol
	{margin-bottom:0cm;}
ul
	{margin-bottom:0cm;}
div.MsoNormal1 {mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
li.MsoNormal1 {mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
p.MsoNormal1 {mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
.style1 {font-size: 14px}
.style2 {color: #FF0000}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman";}
</style>
<![endif]--><!--[if gte mso 9]><xml>
 <o:shapedefaults v:ext="edit" spidmax="2050"/>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:shapelayout v:ext="edit">
  <o:idmap v:ext="edit" data="1"/>
 </o:shapelayout></xml><![endif]-->
</head>

<body lang=EN-US style='tab-interval:36.0pt'>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-37099228-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!--
https://wordhtml.com/
https://www.w3schools.com/html/tryit.asp?filename=tryhtml_basic

https://wordpress.stackexchange.com/questions/360307/possibility-to-control-embedded-video-timeline-with-buttons-and-links-external-t
-->

<div class=Section1>
  <p>&nbsp;</p>
  <div align="center">

  <table width="75%" border="0"><tr>
  <td align="left"></td>
  <td align="right"><a href="Lec2.html">>>> Next 10 Lectures >>> </a></td>
  </tr></table>

  <table width="75%" border="1">
    <tr>
      <td colspan="3"><div align="center">
          <p><strong><em><font color="#CC0000">EE 503 Lectures (Fall 2020/21)</font></em></strong></p>
        </div></td>
    </tr>
    <tr>
      <td width="11%">Lec. #1 </td>
      <td width="65%"><p><a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=1&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture">00:00</a>
          Introduction<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=115&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture">01:55</a>
          Communication example (motivation)<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=585&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture">09:45</a>
          Loss functions (communication example)<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=821&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture">13:41</a>
          Risk/Cost (communication example)<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=1118&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" >18:38</a>
          Restricting the estimator to linear estimation (communication example)<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=1210&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" >20:10</a>
          LMMSE Problem (communication example)<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=1605&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" >26:45</a>
          Connection with practice through law of large numbers (communication
          example)<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=1633&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture">27:13</a>
          Law of large numbers (communication example)<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=2000&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture">33:20</a>
          Average behavior and one time events<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=2337&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture">38:57</a>
          P implies Q (Mathematical Reasoning)<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=2390&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture">39:50</a>
          Necessary, Sufficient conditions<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=2520&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture">42:00</a>
          Truth table (P implies Q)<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=2920&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture">48:40</a>
          Direct Proof Approach (P implies Q)<br />
          <a target="Lec1YT" href="https://www.youtube.com/embed/Hn-jLx-o-Vw?start=3068&autoplay=1" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture">51:08</a>
          Proof by Contraposition (P implies Q)</p>
        <p><strong>Correction:</strong> @47:30 and around: &quot;P:True and Q:False&quot;
          should be &quot;P: False and Q:True&quot; (Ugur Berk S.)</p></td>
      <td width="24%"><iframe name="Lec1YT" width="560" height="315" src="https://www.youtube.com/embed/Hn-jLx-o-Vw" frameborder="0" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #2</td>
      <td><p> <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=1&autoplay=1">00:00</a>
          - Proof by Contradiction (P implies Q) <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=332&autoplay=1">05:32</a>
          - "if and only if" statement <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=645&autoplay=1">10:45</a>
          - Proving "if and only if " statements <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=785&autoplay=1">13:05</a>
          - Comments: Q as an indicator in P implies Q <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=865&autoplay=1">14:25</a>
          - Comments: Many necessary conditions leading to necessary &amp; sufficient
          cond. <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=1140&autoplay=1">19:00</a>
          - Example: reasoning in a court case (Murder in Kizilay) <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=1555&autoplay=1">25:55</a>
          - Linear Algebra Review <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=1710&autoplay=1">28:30</a>
          - Matrix multiplication <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=1838&autoplay=1">30:38</a>
          - Linear combination <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=1906&autoplay=1">31:46</a>
          - Range space of A matrix <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=2025&autoplay=1">33:45</a>
          - Null space of A matrix <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=2193&autoplay=1">36:33</a>
          - Importance of null space in linear equation solutions <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=2410&autoplay=1">40:10</a>
          - Unique solution condition (if there is a solution) <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=2489&autoplay=1">41:29</a>
          - Checking the dimension of Null space <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=2598&autoplay=1">43:18</a>
          - Checking linear independence <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=2635&autoplay=1">43:55</a>
          - Column Rank of A matrix <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=2861&autoplay=1">47:41</a>
          - Projection Matrices <br />
          <a target="Lec2YT" href="https://www.youtube.com/embed/SJ3YL5AuS70?start=3118&autoplay=1">51:58</a>
          - Norm</p>
        <p><strong>Corrections:</strong><br>
          42:30 Additional note: Ax = 0 equation system is assumed to hold true
          for a non-trivial solution, i.e. x \neq 0</p></td>
      <td><iframe name="Lec2YT" width="560" height="315" src="https://www.youtube.com/embed/SJ3YL5AuS70" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #3</td>
      <td><p> <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=1&autoplay=1">0:00</a>
          - Projection Problem (reminder of last lecture) <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=190&autoplay=1">3:10</a>
          - Distance Metric <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=245&autoplay=1">4:05</a>
          - Distance Metric Axioms <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=370&autoplay=1">6:10</a>
          - Norm Function <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=584&autoplay=1">9:44</a>
          - Metric induced from norm function <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=840&autoplay=1">14:00</a>
          - Projection to Range(A) (problem definition) <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=922&autoplay=1">15:22</a>
          - Ever present engineering questions on existence, uniqueness and feasible
          method for solution <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=1149&autoplay=1">19:09</a>
          - Projection to plane (3D case) <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=1568&autoplay=1">26:08</a>
          - Projection to circle example <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=2020&autoplay=1">33:40</a>
          - Projection to a convex set example <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=2182&autoplay=1">36:22</a>
          - Optimality condition for projection (wide angle condition) <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=2482&autoplay=1">41:22</a>
          - Inner product <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=2503&autoplay=1">41:43</a>
          - Inner product axioms <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=2849&autoplay=1">47:29</a>
          - Norm induced by inner product <br />
          <a target="Lec3YT" href="https://www.youtube.com/embed/sp9tu6mO9sw?start=3068&autoplay=1">51:08</a>
          - Cauchy - Schwarz inequality (statement)</p></td>
      <td><iframe name="Lec3YT" width="560" height="315" src="https://www.youtube.com/embed/sp9tu6mO9sw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #4 </td>
      <td><p> <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=1&autoplay=1">0:00</a>
          - Inner Product / Norm Axiom (reminder) <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=120&autoplay=1">2:00</a>
          - Cauchy Schwarz Inequality (proof) <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=520&autoplay=1">8:40</a>
          - Cauchy Schwarz Equality case <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=780&autoplay=1">13:00</a>
          - "angle" between vectors <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=880&autoplay=1">14:40</a>
          - Example: Cosine theorem of 2D/3D Euclidean geometry <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=1200&autoplay=1">20:00</a>
          - Orthogonality of vectors, aligned vectors <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=1470&autoplay=1">24:30</a>
          - Triangle inequality for the induced norm (proof) <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=1660&autoplay=1">27:40</a>
          - Vector spaces, normed spaces, inner product spaces <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=1830&autoplay=1">30:30</a>
          - Projection matrices (problem statement, again!) <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=2067&autoplay=1">34:27</a>
          - Orthogonality conditions for the projection point (projectors) <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=2463&autoplay=1">41:03</a>
          - Orthogonality condition in matrix-vector form (projectors) <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=2579&autoplay=1">42:59</a>
          - Solving the projection point (projectors) <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=2630&autoplay=1">43:50</a>
          - Case of invertible Gram matrix (Solving the projection point) <br />
          <a target="Lec4YT" href="https://www.youtube.com/embed/Zr6uEkPIhTM?start=2730&autoplay=1">45:30</a>
          - Projection matrix expression (finally!)</p>
        <p><strong>Corrections</strong>:<br>
          11:05 x = \lambda_x y should be x = - \lambda_x y (Ugur Berk S.)<br>
          15:30 (x,y) inner product should be (x,y) = x1 \times y1 + x2 \times
          y2 (Ada G.)</p></td>
      <td><iframe name="Lec4YT" width="560" height="315" src="https://www.youtube.com/embed/Zr6uEkPIhTM" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #5</td>
      <td><p> <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=1&autoplay=1">0:00</a>
          - Case of non-invertible Gram matrix (extra!) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=175&autoplay=1">2:55</a>
          - Gram matrix definition and linear independence of vectors <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=280&autoplay=1">4:40</a>
          - Range(A^T x A ) = Range (A^T) proof by SVD (extra!) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=405&autoplay=1">6:45</a>
          - Mini talk about SVD (extra!) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=597&autoplay=1">9:57</a>
          - Orthogonal Projectors (definition) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=790&autoplay=1">13:10</a>
          - Symmetric/Hermitian symmetric matrices (definition) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=880&autoplay=1">14:40</a>
          - Showing P_A is an orthogonal projector <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=1043&autoplay=1">17:23</a>
          - Transpose operation { (ABC)^T = C^T x B^T x A^T } <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=1160&autoplay=1">19:20</a>
          - Symmetric/Hermitian symmetric eigenvectors are orthogonal (statement
          only!) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=1200&autoplay=1">20:00</a>
          - More general fact: Eigenvectors of normal matrices (statement only!)
          <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=1290&autoplay=1">21:30</a>
          - Orthogonal matrices (definition) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=1418&autoplay=1">23:38</a>
          - Gram matrix as matrix of inner products (orthogonal matrices) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=1610&autoplay=1">26:50</a>
          - Eigenspace of P_A <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=1660&autoplay=1">27:40</a>
          - Eigenvalues of P_A (eigenspace P_A) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=1885&autoplay=1">31:25</a>
          - Eigenvectors of P_A (eigenspace P_A) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=1920&autoplay=1">32:00</a>
          - Eigendecomposition expression (eigenspace P_A) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=2350&autoplay=1">39:10</a>
          - Multiplication of matrices A and B via the columns of and rows of
          B <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=2622&autoplay=1">43:42</a>
          - Eigendecomposition expression (eigenspace P_A, finally!) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=2785&autoplay=1">46:25</a>
          - On the representation basis and P_A matrix (uniqueness of P_A) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=3207&autoplay=1">53:27</a>
          - Complementary Projector (definition) <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=3400&autoplay=1">56:40</a>
          - Orthogonality of P_A and P_A^\perp matrices <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=3515&autoplay=1">58:35</a>
          - Eigendecomposition of complementary projector <br />
          <a target="Lec5YT" href="https://www.youtube.com/embed/MBWHnaitu7g?start=3760&autoplay=1">1:02:40</a>
          - Decomposition of vector b to Range(A) space and its complementary
          space</p>
        <p><strong>Corrections:</strong> <br>
          55:55 - Left side of the board, point 2: ( P_A^\perp )^T = ( P_A^\perp
          )^T should be ( P_A^\perp )^T = P_A^\perp</p></td>
      <td><iframe name="Lec5YT" width="560" height="315" src="https://www.youtube.com/embed/MBWHnaitu7g" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #6</td>
      <td><p>
<a target="Lec6YT" href="https://www.youtube.com/embed/pb9dwHbscJE?start=1&autoplay=1">0:00</a>
          - Orthogonal Basis Representations <br />
          <a target="Lec6YT" href="https://www.youtube.com/embed/pb9dwHbscJE?start=430&autoplay=1">7:10</a>
          - Projection operator with orthonormal basis  <br />
          <a target="Lec6YT" href="https://www.youtube.com/embed/pb9dwHbscJE?start=952&autoplay=1">15:52</a>
          - Example 1: Canonical Basis  <br />
          <a target="Lec6YT" href="https://www.youtube.com/embed/pb9dwHbscJE?start=1035&autoplay=1">17:15</a>
          - Example 2: DFT Basis  <br />
          <a target="Lec6YT" href="https://www.youtube.com/embed/pb9dwHbscJE?start=1350&autoplay=1">22:30</a>
          -  Inner product definition for complex-valued vectors <br />
          <a target="Lec6YT" href="https://www.youtube.com/embed/pb9dwHbscJE?start=1950&autoplay=1">32:30</a>
          - Gram-Schmidt Orthogonalization <br />
          <a target="Lec6YT" href="https://www.youtube.com/embed/pb9dwHbscJE?start=2670&autoplay=1">44:30</a>
          - QR decomposition and Gram-Schmidt relation
</p>
<p><strong>Corrections:</strong> <br>
          19:30 - N'th row N'th column of F matrix should be W^{(N-1)x(N-1)} (Gulin
          T.) </p></td>
      <td>

<iframe name="Lec6YT" width="560" height="315" src="https://www.youtube.com/embed/pb9dwHbscJE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>

    <tr>
      <td>Lec. #7</td>
            <td><p>
<a target="Lec7YT" href="https://www.youtube.com/embed/jkGT1d00was?start=1&autoplay=1">0:00</a>
          - Introduction <br />
          <a target="Lec7YT" href="https://www.youtube.com/embed/jkGT1d00was?start=60&autoplay=1">1:00</a>
          - Quadratics (1 independent variable)  <br />
          <a target="Lec7YT" href="https://www.youtube.com/embed/jkGT1d00was?start=720&autoplay=1">12:00</a>
          - Quadratics (2 independent variables)  <br />
          <a target="Lec7YT" href="https://www.youtube.com/embed/jkGT1d00was?start=780&autoplay=1">13:00</a>
          - Level curves of J(x,y) <br />
          <a target="Lec7YT" href="https://www.youtube.com/embed/jkGT1d00was?start=1070&autoplay=1">17:50</a>
          -  Quadratic form : J(x) = x' A x + b'x + c  <br />
          <a target="Lec7YT" href="https://www.youtube.com/embed/jkGT1d00was?start=1230&autoplay=1">20:30</a>
          - Discussion on x' A x term <br />
          <a target="Lec7YT" href="https://www.youtube.com/embed/jkGT1d00was?start=1485&autoplay=1">24:45</a>
          - Gradient of J(x) = (A + A')x + b<br />
		  <a target="Lec7YT" href="https://www.youtube.com/embed/jkGT1d00was?start=1990&autoplay=1">33:10</a>
          - Ju(u) = Jx(u+x_opt)  <br />
          <a target="Lec7YT" href="https://www.youtube.com/embed/jkGT1d00was?start=2460&autoplay=1">41:00 </a>
          - Positive Definite Matrices (definition)  <br />
          <a target="Lec7YT" href="https://www.youtube.com/embed/jkGT1d00was?start=2700&autoplay=1">45:00 </a>
          -  Relation between positive definite matrices and eigenvalues <br />
          <a target="Lec7YT" href="https://www.youtube.com/embed/jkGT1d00was?start=3310&autoplay=1">55:10 </a>
          - Indefinite matrices (definition) <br />
          <a target="Lec7YT" href="https://www.youtube.com/embed/jkGT1d00was?start=3420&autoplay=1">57:00</a>
          - Positive (semi) definiteness checks <br />	



</p>
<p><strong>Corrections:</strong> <br>
          30:00 - 2a11 + a12y + ... should be 2a11x + a12y + .... (similarly for the line below) (Gulin T.) <br />
<br />
				
          45:30  - A = [2 4; 4 2] should be A = [ 1 2; 2 1] ([2 4; 4 2] is the Hessian matrix of J(x,y) which is 2 x [1 2; 2 1]; This explanation is also OK.; but I would like to investigate the nature of quadratic terms u^T A u in this discussion. All explanations are correct, but possibly confusing since it is not clear why we switch to 2 \times A, instead of A = [ 1 2; 2 1]) (Gulin T.)<br />
<br />
          50:17 - The vector [1 -1] points in the opposite direction shown, no harm in this presentation since -1 x [1 -1]  = [-1 1] is also an eigenvector and I am considering the values of the function on the eigenvector \times "t" where  t  is in (-\infty, \infty) (Onur Selim K.)
</td>

      <td><iframe name="Lec7YT" width="560" height="315" src="https://www.youtube.com/embed/jkGT1d00was" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #8</td>
      <td><p>
<a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=1&autoplay=1">0:00</a>
          - Positive Definite Matrices (case of non-symmetric matrices) <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=430&autoplay=1">7:10</a>
          - Over-determined equation systems  <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=540&autoplay=1">9:00</a>
          - Tall matrices / Fat and Short matrices  <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=606&autoplay=1">10:06</a>
          - Minimizing || Ax - b||^2  <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=915&autoplay=1">15:15</a>
          - Solving A^T A x = A^T b (Normal Equation) <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=1097&autoplay=1">18:17</a>
          - Positive Definiteness of A^T A <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=1395&autoplay=1">23:15</a>
          - Review of some DSP Topics <br />
		  <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=1414&autoplay=1">23:34</a>
          - Analog / Continuous Time SP <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=1470&autoplay=1">24:30 </a>
          - LTI systems <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=1530&autoplay=1">25:30 </a>
          - Example: RC circuit (Low-pass filter) <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=1666&autoplay=1">27:46 </a>
          - Discrete-time processing of analog signals (block diagram)<br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=1862&autoplay=1">31:02</a>
          - D/C Conversion  <br />
		  <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=1937&autoplay=1">32:17</a>
          - D/C Conversion (zero-order hold interpolation)   <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=2130&autoplay=1">35:30</a>
          - D/C Conversion (linear interpolation)  <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=2360&autoplay=1">39:20</a>
          - D/C Conversion (sinc interpolation) <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=2638&autoplay=1">43:58</a>
          - sinc(x) (definition)  <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=2820&autoplay=1">47:00</a>
          - sinc interpolation (further explained)  <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=3145&autoplay=1">52:25</a>
          - Discrete-time processing of analog signals (block diagram) <br />
		  <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=3230&autoplay=1">53:50</a>
          - Discrete-time processing of analog signals (bandlimited signals)  <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=3300&autoplay=1">55:00 </a>
          - Some problems of analog signal processing (discussion)  <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=3410&autoplay=1">56:50 </a>
          - Exact discrete-time implementation of analog systems via impulse invariance  <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=3993&autoplay=1">1:06:33</a>
          - Fourier Transform (definition) <br />
          <a target="Lec8YT" href="https://www.youtube.com/embed/BMNEOEHxGiA?start=4100&autoplay=1">1:08:20</a>
          - Fourier Transform of rect(t/T) <br /></td>

      <td><iframe name="Lec8YT" width="560" height="315" src="https://www.youtube.com/embed/BMNEOEHxGiA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #9</td>
      <td><p>
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=1&autoplay=1">0:00</a> - Review of Probability Concepts <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=60&autoplay=1">1:00</a> - Sample Space, Outcome, Event, Probability<br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=380&autoplay=1">6:20</a> - Kolmogorov's Probability Axioms <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=582&autoplay=1">9:42</a> - De Morgan's Laws <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=830&autoplay=1">13:50</a> - Brief Note on sigma algebra <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=1130&autoplay=1">18:50</a> - Random variable <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=1263&autoplay=1">21:03</a> - Random vector <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=1575&autoplay=1">26:15</a> - X = x, X: random variable, x: its value <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=1630&autoplay=1">27:10</a> - c.d.f. (cumulative density function) <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=1820&autoplay=1">30:20</a> - p.d.f. (probability density function) <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=2042&autoplay=1">34:02</a> - Probability value as "area under density" <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=2383&autoplay=1">39:43</a> - Units of density function and probability <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=2517&autoplay=1">41:57</a> - Probability mass functions <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=2602&autoplay=1">43:22</a> - Independence of events A and B <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=2665&autoplay=1">44:25</a> - Independence of random variables X and Y <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=2845&autoplay=1">47:25</a> - c.d.f/p.d.f for joint representation of X and Y <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=3050&autoplay=1">50:50</a> - Conditional Probability <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=3570&autoplay=1">59:30</a> - Conditional random variables <br />
  <a target="Lec9YT" href="https://www.youtube.com/embed/yShJ86SmdMU?start=3700&autoplay=1">1:01:40</a> - Bayes' Theorem
</p></td>
      <td><iframe name="Lec9YT" width="560" height="315" src="https://www.youtube.com/embed/yShJ86SmdMU" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #10</td>
      <td><p>
<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=1&autoplay=1">0:00</a>
      	- Conditional Probability (review)   <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=150&autoplay=1">02:30</a>
      	- Bayes' Theorem (review)   <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=238&autoplay=1">03:58</a>
      	- Marginalization operation (two random variables)   <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=740&autoplay=1">12:20 </a>
      	- Total Probability Theorem <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=954&autoplay=1">15:54 </a>
      	- Example: X is 1 if Heads, X is Unif([0,2]) if Tails <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=1983&autoplay=1">33:03 </a>
      	- Expectation Operation <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=2085&autoplay=1">34:45 </a>
      	- Expectation (law of large numbers interpretation)  <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=2391&autoplay=1">39:51 </a>
      	- E{ g(X) }  <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=2450&autoplay=1">40:50 </a>
      	-  Moments, E{ X^k }   <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=2490&autoplay=1">41:30 </a>
      	- Central Moments, E{ (X - Xbar)^k }  <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=2668&autoplay=1">44:28 </a>
      	- Moment generating function   <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=3127&autoplay=1">52:07 </a>
      	-  Moments as partial description of a r.v.     <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=3214&autoplay=1">53:34 </a>
      	-  Conditional Expectation    <br />
      	<a target="Lec10YT" href="https://www.youtube.com/embed/Si-kMy_7_JY?start=3472&autoplay=1">57:52 </a>
      	- Iterated Expectation  <br /></td>
      <td><iframe name="Lec10YT" width="560" height="315" src="https://www.youtube.com/embed/Si-kMy_7_JY" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
  </table>
<table width="75%" border="0"><tr>
  <td align="left"></td>
  <td align="right"><a href="Lec2.html">>>> Next 10 Lectures >>> </a></td>
  </tr>
</table>
</div>


<div class=Section1 style2>

<p class=MsoNormal align=center style='text-align:center'>&nbsp;</p>
<p align=center class=MsoNormal  style='text-align:center'>
  <o:p>&nbsp;</o:p>
</p>
  <p class=MsoNormal> <o:p>&nbsp;</o:p>
  <p class=MsoNormal>&nbsp;
  <p class=MsoNormal>&nbsp;
  <p class=MsoNormal>&nbsp;
  <div align="center"><strong>EE 503 Statistical Signal Processing and Modeling
    </strong><br>
    <strong>(Fall 2019&ndash; 2020)</strong></div>
  </p>

<table align=center width=75% border="0">
    <tr>
      <td><p class="style1"><strong>Short Description: </strong></p>
        <p class="style1"> This course is the first course on statistical signal
          processing in the graduate curriculum of Department of Electrical and
          Electronics Engineering, Middle East Technical University (METU). Topics
          covered in this course are random vectors, random processes, stationary
          random processes, wide sense stationary processes and their processing
          with LTI systems with applications in optimal filtering, smoothing and
          prediction. A major goal is to introduce the concept of mean square
          error (MSE) optimal processing of random signals by LTI systems. <br>
          <br>
          For the processing of the random signals, it is assumed that some statistical
          information about the signal of interest and distortion is known. By
          utilizing this information, MSE optimal LTI filters (Wiener filters)
          are designed. This forms the processing part of the course. The estimation
          of the statistical information to construct Wiener filters forms the
          modeling part of the course. In the modeling part, we examine AR, MA,
          ARMA models for random signals and give a brief discussion of Pade,
          Prony methods for the deterministic modeling. Among other topics of
          importance are decorrelating transforms (whitening), spectral factorization,
          Karhunen-Loeve transform <br>
          <br>
          This course is a natural pre-requisite (not a formal one) to EE5506
          Advanced Statistical Signal Processing. The estimation theory topics
          in EE 503 is mostly limited to the moment description of random processes
          which forms a special, but the most important, case of EE 5506. </p>
        <p class="style1"><strong>Outline of Topics: </strong></p>
        <ol start="1" type="1" class="style1">
          <li>Review</li>
          <ol start="1" type="a">
            <li> Basics of Mathematical Deduction
              <ol>
                <li> Necessary, Sufficient Conditions</li>
                <li> Proofs via contradiction, contraposition</li>
              </ol>
            </li>
            <li>Basics of Linear Algebra
              <ol>
                <li>Linear independence of vectors (points in linear space)</li>
                <li>Range and Null space of the combination process</li>
                <li> Projection to Range/Null Space (orthogonality principle)
                </li>
                <li>Positive Definite Matrices</li>
              </ol>
            </li>
            <li>Basics of Probability
              <ol>
                <li> Probability as a mapping, axioms, conditional probability</li>
                <li>Expectation, law of large numbers</li>
                <li>Moments, moment generating function</li>
              </ol>
            </li>
          </ol>
          <br>
          <li>Random Processes
            <ol>
              <li>Random variables, random vectors (or a sequence of random variables),
                moment descriptions (mean, variance, correlation), decorrelating
                transforms</li>
              <li>Random processes, stationarity, wide Sense Stationarity (WSS),
                power spectral density, spectral factorization, linear time invariant
                processing of WSS random processes, ergodicity </li>
            </ol>
            <br>
            Ref: Therrien, Hayes, Papoulis, Ross<br>&nbsp
			</li>
          <li>Signal Modeling
            <ol>
              <li>LS methods, Pade, Prony (Deterministic methods)</li>
              <li>AR, MA, ARMA Processes (Stochastic approach), Yule-Walker Equations,
                Non-linear set of equations for MA system fit</li>
              <li> Harmonic Processes </li>
            </ol>
            <br>
            Ref: Hayes, Papoulis <br>&nbsp
          <li>Estimation Theory Topics
            <ol>
              <li>Random parameter estimation
                <ol>
                  <li>Cost function, loss function, square error, absolute error</li>
                  <li> Conditional mean (regression line) as the minimum mean
                    square error (MSE) estimator, orthogonality properties</li>
                  <li> Linear minimum mean square error (LMMSE) estimators, orthogonality
                    principle </li>
                  <li>Regression line, orthogonality </li>
                  <li>FIR, IIR, Causal–IIR Wiener filters</li>
                  <li>Linear Prediction, backward prediction</li>
                  <li>Random vector LMMSE estimation (multiple parameter)</li>
                </ol>
              </li>
              <li>Non-random parameter estimation
                <ol>
                  <li>Maximum likelihood method</li>
                  <li> Best Linear Unbiased Estimator (BLUE)</li>
                  <li>Discussion of linear estimators for the linear observation
                    model y=Ax+n</li>
                </ol>
              </li>
              <li>Karhunen – Loeve Transform</li>
            </ol>
            <br>
            Ref: Therrien, Hayes<br>&nbsp
        </ol>
        </li>
        <strong>References: </strong><br>
        <p class="style1">[Hayes]: M. H. Hayes, Statistical Signal Processing and Modeling, Wiley,
        New York, NY, 1996.</p>
        <p class="style1">[Therrien]: C. W. Therrien, Discrete random signals
          and statistical signal processing, Prentice Hall, c1992.</p>
        <p class="style1">[Papoulis]: A. Papoulis, Probability, Random Variables,
          and Stochastic Processes, 3rd edition, McGraw Hill, 1991. </p>
        <p class="style1">[Ross]: S. M. Ross, Introduction to probability models,
          7th ed. Harcourt Academic Press, 2000.</p>
        </td>
  </tr>
</table>

</div>
</body>

</html>
