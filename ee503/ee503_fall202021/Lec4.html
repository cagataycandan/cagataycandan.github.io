<html xmlns:v="urn:schemas-microsoft-com:vml"
xmlns:o="urn:schemas-microsoft-com:office:office"
xmlns:w="urn:schemas-microsoft-com:office:word"
xmlns:st1="urn:schemas-microsoft-com:office:smarttags"
xmlns="http://www.w3.org/TR/REC-html40">

<head>
<meta http-equiv=Content-Type content="text/html; charset=windows-1252">
<meta name=ProgId content=Word.Document>
<meta name=Generator content="Microsoft Word 10">
<meta name=Originator content="Microsoft Word 10">
<link rel=File-List href="outline_files/filelist.xml">
<title>EE 503 Signal Analysis and Processing</title>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="place"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="City"/>
<o:SmartTagType namespaceuri="urn:schemas-microsoft-com:office:smarttags"
 name="State"/>
<!--[if gte mso 9]><xml>
 <o:DocumentProperties>
  <o:Author>METU-EEE</o:Author>
  <o:LastAuthor>EEE</o:LastAuthor>
  <o:Revision>2</o:Revision>
  <o:TotalTime>23</o:TotalTime>
  <o:Created>2007-09-21T10:56:00Z</o:Created>
  <o:LastSaved>2007-09-21T10:56:00Z</o:LastSaved>
  <o:Pages>1</o:Pages>
  <o:Words>750</o:Words>
  <o:Characters>4278</o:Characters>
  <o:Company>METU-EEE</o:Company>
  <o:Lines>35</o:Lines>
  <o:Paragraphs>10</o:Paragraphs>
  <o:CharactersWithSpaces>5018</o:CharactersWithSpaces>
  <o:Version>10.2625</o:Version>
 </o:DocumentProperties>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <w:WordDocument>
  <w:SpellingState>Clean</w:SpellingState>
  <w:GrammarState>Clean</w:GrammarState>
  <w:Compatibility>
   <w:BreakWrappedTables/>
   <w:SnapToGridInCell/>
   <w:WrapTextWithPunct/>
   <w:UseAsianBreakRules/>
  </w:Compatibility>
  <w:BrowserLevel>MicrosoftInternetExplorer4</w:BrowserLevel>
 </w:WordDocument>
</xml><![endif]--><!--[if !mso]><object
 classid="clsid:38481807-CA0E-42D2-BF39-B33AF135CC4D" id=ieooui></object>
<style>
st1\:*{behavior:url(#ieooui) }
</style>
<![endif]-->
<style>
<!--
 /* Font Definitions */
 @font-face
	{font-family:Wingdings;
	panose-1:5 0 0 0 0 0 0 0 0 0;
	mso-font-charset:2;
	mso-generic-font-family:auto;
	mso-font-pitch:variable;
	mso-font-signature:0 268435456 0 0 -2147483648 0;}
 /* Style Definitions */
 p.MsoNormal, li.MsoNormal, div.MsoNormal
	{mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
span.SpellE
	{mso-style-name:"";
	mso-spl-e:yes;}
span.GramE
	{mso-style-name:"";
	mso-gram-e:yes;}
@page Section1
	{size:612.0pt 792.0pt;
	margin:72.0pt 90.0pt 72.0pt 90.0pt;
	mso-header-margin:35.4pt;
	mso-footer-margin:35.4pt;
	mso-paper-source:0;}
div.Section1
	{page:Section1;}
 /* List Definitions */
 @list l0
	{mso-list-id:24134985;
	mso-list-type:hybrid;
	mso-list-template-ids:1418224520 67698703 67698713 67698715 67698703 67698713 67698715 67698703 67698713 67698715;}
@list l0:level1
	{mso-level-tab-stop:36.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;}
@list l0:level2
	{mso-level-number-format:alpha-lower;
	mso-level-tab-stop:72.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;}
@list l0:level3
	{mso-level-number-format:roman-lower;
	mso-level-tab-stop:108.0pt;
	mso-level-number-position:right;
	text-indent:-9.0pt;}
@list l0:level4
	{mso-level-tab-stop:144.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;}
@list l0:level5
	{mso-level-number-format:alpha-lower;
	mso-level-tab-stop:180.0pt;
	mso-level-number-position:left;
	text-indent:-18.0pt;}
ol
	{margin-bottom:0cm;}
ul
	{margin-bottom:0cm;}
div.MsoNormal1 {mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
li.MsoNormal1 {mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
p.MsoNormal1 {mso-style-parent:"";
	margin:0cm;
	margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:12.0pt;
	font-family:"Times New Roman";
	mso-fareast-font-family:"Times New Roman";}
.style1 {font-size: 14px}
.style2 {color: #FF0000}
-->
</style>
<!--[if gte mso 10]>
<style>
 /* Style Definitions */
 table.MsoNormalTable
	{mso-style-name:"Table Normal";
	mso-tstyle-rowband-size:0;
	mso-tstyle-colband-size:0;
	mso-style-noshow:yes;
	mso-style-parent:"";
	mso-padding-alt:0cm 5.4pt 0cm 5.4pt;
	mso-para-margin:0cm;
	mso-para-margin-bottom:.0001pt;
	mso-pagination:widow-orphan;
	font-size:10.0pt;
	font-family:"Times New Roman";}
</style>
<![endif]--><!--[if gte mso 9]><xml>
 <o:shapedefaults v:ext="edit" spidmax="2050"/>
</xml><![endif]--><!--[if gte mso 9]><xml>
 <o:shapelayout v:ext="edit">
  <o:idmap v:ext="edit" data="1"/>
 </o:shapelayout></xml><![endif]-->
</head>

<body lang=EN-US style='tab-interval:36.0pt'>

<script type="text/javascript">

  var _gaq = _gaq || [];
  _gaq.push(['_setAccount', 'UA-37099228-1']);
  _gaq.push(['_trackPageview']);

  (function() {
    var ga = document.createElement('script'); ga.type = 'text/javascript'; ga.async = true;
    ga.src = ('https:' == document.location.protocol ? 'https://ssl' : 'http://www') + '.google-analytics.com/ga.js';
    var s = document.getElementsByTagName('script')[0]; s.parentNode.insertBefore(ga, s);
  })();

</script>

<!--
https://wordhtml.com/
https://www.w3schools.com/html/tryit.asp?filename=tryhtml_basic

https://wordpress.stackexchange.com/questions/360307/possibility-to-control-embedded-video-timeline-with-buttons-and-links-external-t
-->

<div class=Section1>
  <p>&nbsp;</p>
  <div align="center">
   <table width="75%" border="0"><tr>
  <td align="left"><a href="Lec3.html"><<< Previous 10 Lectures <<< </a></td>
  <td></td>
  </tr>
  </table>
  <table width="75%" border="1">
    <tr>
      <td colspan="3"><div align="center">
          <p><strong><em><font color="#CC0000">EE 503 Lectures (Fall 2020/21)</font></em></strong></p>
        </div></td>
    </tr>
    <tr>
      <td width="11%">Lec. #31 </td>
      <td width="67%"><p><a target="Lec31YT" href="https://www.youtube.com/embed/BpMnRhZ_lXE?start=1&autoplay=1">00:00</a> - Example: f(x,y) uniform in 1x1 square in 1st and 3rd quadrants (revisited, Lec.30) <br />
  <a target="Lec31YT" href="https://www.youtube.com/embed/BpMnRhZ_lXE?start=315&autoplay=1">05:15</a> - Another proof min MSE via orthogonality (example) <br />
  <a target="Lec31YT" href="https://www.youtube.com/embed/BpMnRhZ_lXE?start=1042&autoplay=1">17:22</a> - Uncorrelated check for error of min.MSE estimator with x^k, k:odd! <br />
  <a target="Lec31YT" href="https://www.youtube.com/embed/BpMnRhZ_lXE?start=1750&autoplay=1">29:10</a> - Example: x = y + n, y and n zero-mean jointly Gaussian, find min. MSE yhat(x). <br />
  <a target="Lec31YT" href="https://www.youtube.com/embed/BpMnRhZ_lXE?start=2930&autoplay=1">48:50</a> - Conclusion #1: For jointly gaussian rv's, the posterior density is Gaussian <br />
  <a target="Lec31YT" href="https://www.youtube.com/embed/BpMnRhZ_lXE?start=3044&autoplay=1">50:44</a> - Conclusion #2: Non-zero mean case is a simple adaptation of zero mean case
</p>
<p>Document for the proof of Conclusion #1: <a href="http://users.metu.edu.tr/ccandan/ee503/ee503_fall201011/lecture_notes/On_Gaussian_Distribution1p2.pdf">.pdf</a>

<p><strong>Corrections:</strong>
<br>12:13 - Unif([a,b+\Delta]) should be Unif([a,a+\Delta]) (Thanks Ugur Berk S.)

<br><br>18:57 - For the explanations given on the board "k: arbitrary integer" should be "k: arbitary **odd** integer" (the results are trivially valid for even valued k, since f(x,y) = f(-x,-y), i.e. symmetric wrt to origin and many integrals with even valued k is equal to zero due to this symmetry) (Thanks Ugur Berk S.)

<br><br>20:23 - sgn(x) x^k = |x|^k is only valid for odd valued k (Thanks Ugur Berk S.) For even valued say k = 2m, 1. E{ sgn(x) x^{2m} } = 0. Since, sgn(x) x^k = sgn(x) x^{2m} is an odd function of "x": Hence E{ sgn(x) x^{2m} } = \int f(x) sgn(x) x^{2m} dx = 0 since f(x) is an even function (i.e. symmetric wrt to origin f(x) = f(-x)) and then the integrand is an odd function. 2. E{ yx^{2m} } = 0. Since g(x,y) = yx^{2m} is odd symmetric with respect to the origin (g(x,y) = - g(-x,-y)); hence, \int \int f(x,y) g(x,y) dx dy = 0. This equality can be verified by a simple exchange of variables x2 = -x, y2=-y, then \int \int f(x,y) g(x,y) dx dy = - \int \int f(x2,y2) g(x2,y2) dx2 dy2 which gives the result of integration as 0. Hence all the results given on the board assume "k" is taken as an odd integer. I am explaining this a bit more in a later lecture, that is in <a href="https://www.youtube.com/watch?v=BpMnRhZ_lXE&amp;t=395s">6:35</a> of Lec. 35a, but I should have clarified this during this lecture, indeed sorry CC)</p>
</td>
      <td width="22%"><iframe name="Lec31YT" width="560" height="315" src="https://www.youtube.com/embed/BpMnRhZ_lXE" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #32</td>
      <td><p><a target="Lec32YT" href="https://www.youtube.com/embed/M1rgHy-kKlo?start=1&autoplay=1">00:00</a> - Linear Minimum Mean Square Error (LMMSE) Estimators <br />
<a target="Lec32YT" href="https://www.youtube.com/embed/M1rgHy-kKlo?start=120&autoplay=1">02:00</a> - Example: LMMSE estimator in the form yhat = ax + b <br />
<a target="Lec32YT" href="https://www.youtube.com/embed/M1rgHy-kKlo?start=304&autoplay=1">05:04</a> - Deriving normal equations, by partial diff. (example) <br />
<a target="Lec32YT" href="https://www.youtube.com/embed/M1rgHy-kKlo?start=659&autoplay=1">10:59</a> - Solving normal equations (example) <br /> <a target="Lec32YT" href="https://www.youtube.com/embed/M1rgHy-kKlo?start=1000&autoplay=1">16:40</a> - LMMSE calculation (example) <br />
<a target="Lec32YT" href="https://www.youtube.com/embed/M1rgHy-kKlo?start=1675&autoplay=1">27:55</a> - Comment #1: LMMSE are parametric estimators not as good as min. MSE est. in general<br />
<a target="Lec32YT" href="https://www.youtube.com/embed/M1rgHy-kKlo?start=1780&autoplay=1">29:40</a> - Comment #2: LMMSE est. = min. MSE est for jointly Gaussian observations and desired r.v. <br />
<a target="Lec32YT" href="https://www.youtube.com/embed/M1rgHy-kKlo?start=1856&autoplay=1">30:56</a> - Comment #3: LMMSE is used in practice, since we only have moment estimates at our disposal <br />
<a target="Lec32YT" href="https://www.youtube.com/embed/M1rgHy-kKlo?start=2031&autoplay=1">33:51</a> - 2nd derivation (more general) for normal Equations (gradient calc.) <br />
<a target="Lec32YT" href="https://www.youtube.com/embed/M1rgHy-kKlo?start=2555&autoplay=1">42:35</a> - Normal equation: R_x w = r_xy <br />
<a target="Lec32YT" href="https://www.youtube.com/embed/M1rgHy-kKlo?start=2731&autoplay=1">45:31</a> - 2nd derivation (more general) for LMMSE value <br />
<a target="Lec32YT" href="https://www.youtube.com/embed/M1rgHy-kKlo?start=3061&autoplay=1">51:01</a> - Example: LMMSE estimator in the form yhat = ax + b (revisited)</p></td>
      <td><iframe name="Lec32YT" width="560" height="315" src="https://www.youtube.com/embed/M1rgHy-kKlo" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #33</td>
      <td><p><a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=0&autoplay=1">00:00:00</a> - LMMSE Estimation (summary) <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=212&autoplay=1">00:03:32</a> - Example: x[n] = c + w[n], c and w[n] uncorrelated zero mean r.v.'s, n={1, ... , N}<br /> <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=320&autoplay=1">00:05:20</a> - Discussing on problem set-up (example) <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=574&autoplay=1">00:09:34</a> - Writing normal equations (example) <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=1143&autoplay=1">00:19:03</a> - Introducing SNR definition (example) <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=1380&autoplay=1">00:23:00</a> - Solving normal equations (example) <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=1900&autoplay=1">00:31:40</a> - Calculating LMMSE value (example) <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=2070&autoplay=1">00:34:30</a> - Comments: special case of infinite SNR (example) <br /> <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=2088&autoplay=1">00:34:48</a> - Comments: N observations with SNR = 1 or 1 observation with SNR = N <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=2224&autoplay=1">00:37:04</a> - Example: x[n] = c + w[n], c (non-zero mean) and w[n] uncorrelated r.v.'s, n={1, ... , N}<br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=2414&autoplay=1">00:40:14</a> - Introducing SNR definition (example) <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=2510&autoplay=1">00:41:50</a> - Solution of normal equations (example) <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=2577&autoplay=1">00:42:57</a> - Is LMMSE estimator for this problem biased? (example) <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=2837&autoplay=1">00:47:17</a> - Removing bias with an affine estimator (example) <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=3195&autoplay=1">00:53:15</a> - Writing normal equations for affine estimator (example) <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=3545&autoplay=1">00:59:05</a> - Solving normal equations for affine estimator (example) <br />
  <a target="Lec33YT" href="https://www.youtube.com/embed/8TXYbEcfwAs?start=3632&autoplay=1">01:00:32</a> - Finalizing the estimator expression (example)
</p>
<p><strong>Corrections:</strong> <br>
22:33 - NxN entry of the matrix should be 1 + 1/SNR_N (not 1) (Thanks to Ugur Berk S.)
<br><br>
38:50 - E{ \sigma_w1^2 } should be E{ w_1^2}  in E{x_1^2 } = E{c^2} + E{ \sigma_w1^2 } (Thanks to Ege. E)
          </p>
</td>
      <td><iframe name="Lec33YT" width="560" height="315" src="https://www.youtube.com/embed/8TXYbEcfwAs" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #34 </td>
      <td><p><a target="Lec34YT" href="https://www.youtube.com/embed/XhrZPr-lO64?start=1&autoplay=1">00:00</a> - Example: xvec = pvec \times c + nvec; pvec: known vector; c and nvec r.v.'s <br />
  <a target="Lec34YT" href="https://www.youtube.com/embed/XhrZPr-lO64?start=153&autoplay=1">02:33</a> - Derivation of Normal Equations for LMMSE est. (complex valued case) <br />
  <a target="Lec34YT" href="https://www.youtube.com/embed/XhrZPr-lO64?start=782&autoplay=1">13:02</a> - Derivation of LMMSE value (complex valued case) <br />
  <a target="Lec34YT" href="https://www.youtube.com/embed/XhrZPr-lO64?start=1377&autoplay=1">22:57</a> : Link to paper:
  <a href="http://users.metu.edu.tr/ccandan/pub_dir/IEEE_SPM_March_2019_Properly_Handling_Complex_Differentiation.pdf">.pdf</a> <br />
  <a target="Lec34YT" href="https://www.youtube.com/embed/XhrZPr-lO64?start=1503&autoplay=1">25:03</a> - Discussion on the application related with example <br />
  <a target="Lec34YT" href="https://www.youtube.com/embed/XhrZPr-lO64?start=1605&autoplay=1">26:45</a> - Solution for Identity Noise Cov. Mat. (example) <br />
  <a target="Lec34YT" href="https://www.youtube.com/embed/XhrZPr-lO64?start=1838&autoplay=1">30:38</a> - Matrix inversion lemma <br />
  <a target="Lec34YT" href="https://www.youtube.com/embed/XhrZPr-lO64?start=2291&autoplay=1">38:11</a> - Expression for the estimator (example) <br />
  <a target="Lec34YT" href="https://www.youtube.com/embed/XhrZPr-lO64?start=2487&autoplay=1">41:27</a>- Solution for General Noise Cov. Mat. (example) <br />
  <a target="Lec34YT" href="https://www.youtube.com/embed/XhrZPr-lO64?start=2562&autoplay=1">42:42</a> - Solution by whitening (example) <br /> </p>

<p>Matrix Inversion Lemma:
  <a href="https://en.wikipedia.org/wiki/Woodbury_matrix_identity">wikipedia link</a>
</p></td>
<td><iframe name="Lec34YT" width="560" height="315" src="https://www.youtube.com/embed/XhrZPr-lO64" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #35a</td>
      <td><p>
  <a target="Lec35YT" href="https://www.youtube.com/embed/iMXLNafbxM0?start=1&autoplay=1">00:00</a> - Example: x,y unif. dist. in 1x1 square in 1st and 3 quadrants (Lec.30, revisited) <br />
  <a target="Lec35YT" href="https://www.youtube.com/embed/iMXLNafbxM0?start=61&autoplay=1">01:01</a> - Min. MSE Linear/Affine estimator yhat(x) (example) <br />
  <a target="Lec35YT" href="https://www.youtube.com/embed/iMXLNafbxM0?start=390&autoplay=1">06:30</a> - E{yx^k} and E{x^k} expressions (example) <br />
  <a target="Lec35YT" href="https://www.youtube.com/embed/iMXLNafbxM0?start=905&autoplay=1">15:05</a> - Using powers of the observation value in the min. MSE estimator (example) <br />
  <a target="Lec35YT" href="https://www.youtube.com/embed/iMXLNafbxM0?start=1528&autoplay=1">25:28</a> - min. Cubic MSE estimator and its MSE value (example) <br /> <a target="Lec35YT" href="https://www.youtube.com/embed/iMXLNafbxM0?start=1760&autoplay=1">29:20</a> - Higher Order Estimators, Matlab Results (example) link:
  <a href="https://www.youtube.com/watch?v=tnlHE6sVOe0">youtube-link</a> <br />
  <a target="Lec35YT" href="https://www.youtube.com/embed/iMXLNafbxM0?start=1958&autoplay=1">32:38</a> - Properties of LMMSE Estimators <br />
  <a target="Lec35YT" href="https://www.youtube.com/embed/iMXLNafbxM0?start=1963&autoplay=1">32:43</a> - Property 1: Geometric (Vector Space) Interpretation <br /> <a target="Lec35YT" href="https://www.youtube.com/embed/iMXLNafbxM0?start=2537&autoplay=1">42:17</a> - Property 2: Multiple r.v. estimation (Total MSE minimization) <br />
  <a target="Lec35YT" href="https://www.youtube.com/embed/iMXLNafbxM0?start=3257&autoplay=1">54:17</a> - Estimator expression for total MSE minimization (property 2) <br />
  <a target="Lec35YT" href="https://www.youtube.com/embed/iMXLNafbxM0?start=3334&autoplay=1">55:34</a> - Example: xvec = Hyvec + n. Find LMMSE estimator for xvec. (property 2) <br /> <br /> Link to supplementary video for MATLAB content:
  <a href="https://www.youtube.com/watch?v=tnlHE6sVOe0">youtube-link</a>
</p></td>

<td><iframe name="Lec35YT" width="560" height="315" src="https://www.youtube.com/embed/iMXLNafbxM0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
   <tr>
      <td>Lec. #35b</td>
      <td>Supplementary video for Lec. 35a</td>
<td><iframe name="Lec35bYT" width="560" height="315" src="https://www.youtube.com/embed/tnlHE6sVOe0" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #36a</td>
      <td><p><a target="Lec36aYT" href="https://www.youtube.com/embed/6Qwctmc8vHw?start=1&autoplay=1">00:00</a> - Property 3: Linear combination of observations as input to LMMSE estimation <br />
  <a target="Lec36aYT" href="https://www.youtube.com/embed/6Qwctmc8vHw?start=268&autoplay=1">04:28</a> - Recursive estimation discussion <br />
  <a target="Lec36aYT" href="https://www.youtube.com/embed/6Qwctmc8vHw?start=1417&autoplay=1">23:37</a> - Recursive estimator expression <br />
  <a target="Lec36aYT" href="https://www.youtube.com/embed/6Qwctmc8vHw?start=1444&autoplay=1">24:04</a> - Innovation <br />
  <a target="Lec36aYT" href="https://www.youtube.com/embed/6Qwctmc8vHw?start=1515&autoplay=1">25:15</a> - Property 4: LMMSE estimation of a linear combination of desired r.v.'s from same set of observations
</p>
<p><strong>Corrections:</strong> <br>
28:50 - zhat = M yhat should be  zhat = N yhat (Thanks Ugur Berk S.)
</p>

</td>
<td><iframe name="Lec36aYT" width="560" height="315" src="https://www.youtube.com/embed/6Qwctmc8vHw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #36b</td>
      <td><p><a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=1&autoplay=1">00:00</a> - Wiener Filtering (Problem Setup) <br />
  <a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=188&autoplay=1">03:08</a> - FIR Wiener Filtering <br />
  <a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=282&autoplay=1">04:42</a> - Deriving Wiener-Hopf (or normal) Equations <br />
  <a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=1326&autoplay=1">22:06</a> - Min.MSE calculation <br />
  <a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=1500&autoplay=1">25:00</a> - Example: x[n] = d[n] + v[n], r_d[k] = \alpha^{|k|} , r_v[k] = \sigma_v^2 \delta[k] <br />
  <a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=1945&autoplay=1">32:25</a> - Writing Normal equations for 2-tap filter (example) <br /> <a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=2210&autoplay=1">36:50</a> - Calculation of LMMSE value for 2-tap filter (example) <br /> <a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=2442&autoplay=1">40:42</a> - 1-tap FIR Wiener filter derivaiton (example) <br />
  <a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=2706&autoplay=1">45:06</a> - SNR before and after Wiener filtering (example) <br />
  <a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=3090&autoplay=1">51:30</a> - SNR-after with 1-tap Wiener filter (example) <br />
  <a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=3184&autoplay=1">53:04</a> - SNR-after with 2-tap Wiener filter (example) <br />
  <a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=3550&autoplay=1">59:10</a> - What is the maximum SNR-after with 2-tap filter? (example) <br />
  <a target="Lec36bYT" href="https://www.youtube.com/embed/NXd_ebNPxiw?start=3570&autoplay=1">59:30</a> - Max. SNR filter derivation (example)
</p></td>
     <td><iframe name="Lec36bYT" width="560" height="315" src="https://www.youtube.com/embed/NXd_ebNPxiw" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #37</td>
      <td><p><a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=1&autoplay=1">00:00</a> - FIR Wiener filtering (review) <br />
  <a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=270&autoplay=1">4:30</a> - Categorization of Signal Processing Operations <br />
  <a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=287&autoplay=1">4:47</a> - Filtering (categorization) <br />
  <a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=375&autoplay=1">6:15</a> - Smoothing (categorization) <br />
  <a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=800&autoplay=1">13:20</a> - Prediction (categorization) <br />
  <a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=1190&autoplay=1">19:50</a> - Example: Two-tap linear predictor for x[n] with r_x[k] = \alpha^|k| <br />
  <a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=1954&autoplay=1">32:34</a> - Comments: Prediction error as uncorrelated part of the observation <br />
  <a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=2410&autoplay=1">40:10</a> - Comments: Prediction error filter <br />
  <a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=2550&autoplay=1">42:30</a> - Backward prediction <br />
  <a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=2845&autoplay=1">47:25</a> - Auto-correlation of time-reversed WSS process (backward prediction) <br />
  <a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=3020&autoplay=1">50:20</a> - Remark: Auto-correlation matrix estimation with time-reversed vectors for WSS processes<br /> <a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=3257&autoplay=1">54:17</a>- Auto-correlation matrix for the samples of WSS processes (remark) <br />
  <a target="Lec37YT" href="https://www.youtube.com/embed/f9w1qfJvEtA?start=3527&autoplay=1">58:47</a> - Expression for the auto-correlation matrix estimation for WSS process samples (remark)
</p></td>
      <td><iframe name="Lec37YT" width="560" height="315" src="https://www.youtube.com/embed/f9w1qfJvEtA" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #38</td>
      <td><p> <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=1&autoplay=1">00:00:00</a> - FIR Wiener Filtering (review) <br />
   <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=130&autoplay=1">00:02:10</a> - IIR Non-Causal Wiener Filtering <br />
   <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=634&autoplay=1">00:10:34</a> - IIR Non-Causal Wiener filter expression in Fourier domain <br />
   <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=735&autoplay=1">00:12:15</a> - MSE expression for IIR Non-Causal Wiener Filter <br />
   <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=1380&autoplay=1">00:23:00</a> - Filtering application (noise removal) for IIR Non-Causal Wiener filtering <br />
   <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=1615&autoplay=1">00:26:55</a> - Comment #1: Impulse response of IIR Non-Causal Wiener filter is an even sequence<br />
   <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=1700&autoplay=1">00:28:20</a> - Comment #2: IIR Non-Causal Wiener filter processes each spectrum sample independent of other samples <br />
   <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=1826&autoplay=1">00:30:26</a> - Connection between Comment #1 and the forward-backward time invariance of WSS processes (Lec. 37 link: <a href="https://www.youtube.com/watch?v=f9w1qfJvEtA">youtube-link</a>) <br />
   <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=2151&autoplay=1">00:35:51</a> - Connection between Comment #2 and the fact that FT decorrelates WSS processes (Lec 27b link: <a href="https://www.youtube.com/watch?v=H2ruS6QnliI">youtube-link</a>)<br />
   <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=2275&autoplay=1">00:37:55</a> - Pictorial interpretation of IIR Non-Causal Wiener filtering for filtering (noise removal) application <br />
   <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=2504&autoplay=1">00:41:44</a> - MSE calculation for IIR Non-Causal Wiener filtering for filtering (noise removal) application <br />
   <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=2900&autoplay=1">00:48:20</a> - Example: x[n] = d[n] + v[n], r_d[k] = 0.8^|k| , r_v[k] = \delta_v[k], Find IIR NC Wiener filter to estimate d[n]. <br />
   <a target="Lec38YT" href="https://www.youtube.com/embed/7s-1aDNxrAc?start=4025&autoplay=1">1:07:05</a> - MSE calculation for IIR Non-Causal Wiener filter (example)
</p></td>
      <td><iframe name="Lec38YT" width="560" height="315" src="https://www.youtube.com/embed/7s-1aDNxrAc" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #39</td>
      <td><p><a target="Lec39YT" href="https://www.youtube.com/embed/BbQL_e87Ajk?start=0&autoplay=1">00:00</a> - IIR Causal Wiener Filtering <br />
  <a target="Lec39YT" href="https://www.youtube.com/embed/BbQL_e87Ajk?start=133&autoplay=1">02:13</a> - Deriving normal equations by differentiation <br />
  <a target="Lec39YT" href="https://www.youtube.com/embed/BbQL_e87Ajk?start=414&autoplay=1">06:54</a> - Special case: Input is white noise <br />
  <a target="Lec39YT" href="https://www.youtube.com/embed/BbQL_e87Ajk?start=597&autoplay=1">09:57</a> - General case: Decorrelating input to generate white noise input artificially <br />
  <a target="Lec39YT" href="https://www.youtube.com/embed/BbQL_e87Ajk?start=1803&autoplay=1">30:03</a> - IIR Causal Wiener Filter in z-domain <br />
  <a target="Lec39YT" href="https://www.youtube.com/embed/BbQL_e87Ajk?start=2226&autoplay=1">37:06</a> - Example: x[n] = d[n] + v[n], r_d[k] = 0.8^|k|, r_v[k] = \sigma_v^2\delta[k] <br />
  <a target="Lec39YT" href="https://www.youtube.com/embed/BbQL_e87Ajk?start=4184&autoplay=1">01:09:44</a> - Summary of results for 1 Tap, 2 Tap, Causal IIR, Non-Causal IIR Wiener filter result for the same example
</p>
<p><strong>Corrections:</strong> <br>
37:10 - r_v[k] should be r_v[k] = \sigma_v^2 \delta[k] (white noise)
</p>
</td>
      <td><iframe name="Lec39YT" width="560" height="315" src="https://www.youtube.com/embed/BbQL_e87Ajk" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #40</td>
      <td><p><a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=1&autoplay=1">00:00</a> - Ergodicity <br />
  <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=180&autoplay=1">03:00</a> - Mean ergodicity <br />
  <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=242&autoplay=1">04:02</a> - Sample mean estimator <br />
  <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=510&autoplay=1">08:30</a> - Question on the convergence issues for sample mean estimator as N goes to infinity.<br />
  <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=740&autoplay=1">12:20</a> - Unbiasedness of sample mean estimator <br />
  <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=841&autoplay=1">14:01</a> - Consistency of sample mean estimator <br />
  <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=1630&autoplay=1">27:10</a> - Necessary and Sufficient Condition for mean ergodicity <br />
  <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=1744&autoplay=1">29:04</a> - An equivalent necessary and sufficient condition for mean ergodicity <br />
  <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=1780&autoplay=1">29:40</a> - Sufficient condition for mean ergodicity <br />
  <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=1986&autoplay=1">33:06</a> - Example: Mean-ergodic and not mean-ergodic r.p. example <br />
  <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=2940&autoplay=1">49:00</a> - Ergodicity in auto-correlation <br />
  <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=3245&autoplay=1">54:05</a> - Biased and unbiased estimators for auto-correlation <br />
  <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=3490&autoplay=1">58:10</a> - Biased auto-correlation estimators always gives a valid auto-correlation sequence<br /> <a target="Lec40YT" href="https://www.youtube.com/embed/v3Zjb-gahcQ?start=3970&autoplay=1">01:06:10</a> - Consistency of auto-correlation estimator
</p></td>
      <td><iframe name="Lec40YT" width="560" height="315" src="https://www.youtube.com/embed/v3Zjb-gahcQ" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #41</td>
      <td><p><a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=1&autoplay=1">00:00:00</a> - Best Linear Unbiased Estimator (BLUE) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=75&autoplay=1">00:01:15</a> - Illustration of BLUE on a simple sample: x_k = c + w_k, k={1,2}, Find chat_BLUE.<br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=431&autoplay=1">00:07:11</a> - MSE expression for chat (illustration) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=581&autoplay=1">00:09:41</a> - Comment on MSE: Unrealizable estimator unless estimator is unbiased (illustration)<br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=735&autoplay=1">00:12:15</a>- Optimization problem for minimum MSE unbiased estimator (illustration) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=1155&autoplay=1">00:19:15</a> - Solution for uncorrelated noise (illustration) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=1354&autoplay=1">00:22:34</a> - Precision = 1/noise-variance definition (illustration) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=1725&autoplay=1">00:28:45</a> - Comparison with a similar random parameter estimation problem (Lec.33 link : <a href="https://youtu.be/8TXYbEcfwAs?t=2224">youtube-link</a>) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=1864&autoplay=1">00:31:04</a> - General Case for the BLUE estimator <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=2027&autoplay=1">00:33:47</a> - Total MSE derivation (general case) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=2186&autoplay=1">00:36:26</a> - Condition for the unbiased estimator (general case) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=2467&autoplay=1">00:41:07</a> - Total MSE expression (general case) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=2657&autoplay=1">00:44:17</a> - Optimization problem for BLUE estimator (general case) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=2843&autoplay=1">00:47:23</a> - BLUE Estimator expression (general case) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=2985&autoplay=1">00:49:45</a> - Total MSE expression for BLUE estimator (general case) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=3097&autoplay=1">00:51:37</a>- Special case #1: White noise (Rn = \sigma_n^2 \times Identity ) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=3270&autoplay=1">00:54:30</a> - Comment on case #1: LS solution is the BLUE for white noise <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=3355&autoplay=1">00:55:55</a> - Special case #2: Non-white noise (Rn \neq \sigma_n^2 \times Identity ) <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=3736&autoplay=1">01:02:16</a> - Comment on case #2: Whitened LS solution is the BLUE estimator <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=3810&autoplay=1">01:03:30</a> - Revisiting earlier illustrative example <br />
  <a target="Lec41YT" href="https://www.youtube.com/embed/9FqId7cm7ho?start=4106&autoplay=1">01:08:26</a> - Comparison with random parameter case, LMMSE estimation (general case)
</p></td>
      <td><iframe name="Lec41YT" width="560" height="315" src="https://www.youtube.com/embed/9FqId7cm7ho" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
    <tr>
      <td>Lec. #42</td>
      <td><p>
<a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=1&autoplay=1">00:00:00</a> - Introduction to the end of EE 503! <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=30&autoplay=1">00:00:30</a> - Karhunen Loeve (KL) Transform <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=237&autoplay=1">00:03:57</a> - Desired properties for the KL transformation <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=388&autoplay=1">00:06:28</a> - KL Transformation for 1-dimensional approximation (1D case) <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=865&autoplay=1">00:14:25</a> - MSE expression for the problem (1D case) <br /> <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=1403&autoplay=1">00:23:23</a> - MSE minimizing solution (1D case) <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=1515&autoplay=1">00:25:15</a> - Eigenvectors of R_x matrix (reminder) <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=1756&autoplay=1">00:29:16</a> - Solution for optimal sub-space (1D case) <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=1920&autoplay=1">00:32:00</a> - min. MSE expression (1D case) <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=2028&autoplay=1">00:33:48</a> - KL Transformation for 2-dimensional approximation (2D case) <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=2336&autoplay=1">00:38:56</a> - Reduction to the 1D approximation case (2D case) <br />   <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=3374&autoplay=1">00:56:14</a> - Solution for optimal sub-space (2D case) <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=3447&autoplay=1">00:57:27</a> - min. MSE expression (2D case) <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=3810&autoplay=1">01:03:30</a> - Comment on the uncorrelatedness of expansion coefficients <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=3955&autoplay=1">01:05:55</a> - KL transformation (General case) <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=4036&autoplay=1">01:07:16</a> - Comment: Application Example: Signal Compression <br /> <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=4474&autoplay=1">01:14:34</a> - Comment: Case of WSS processes (Lec. 23b link:
  <a href="https://youtu.be/H2ruS6QnliI?t=448">youtube-link</a>) <br />
  <a target="Lec42YT" href="https://www.youtube.com/embed/NfAyEZk26m8?start=5546&autoplay=1">01:32:26</a> - Goodbye!
</p></td>
      <td><iframe name="Lec42YT" width="560" height="315" src="https://www.youtube.com/embed/NfAyEZk26m8" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe></td>
  </table>

  <table width="75%" border="0"><tr>
  <td align="left"><a href="Lec3.html"><<< Previous 10 Lectures <<< </a></td>
  <td></td>
  </tr>
  </table>
</div>


<div class=Section1 style2>

<p class=MsoNormal align=center style='text-align:center'>&nbsp;</p>
<p align=center class=MsoNormal  style='text-align:center'>
  <o:p>&nbsp;</o:p>
</p>
  <p class=MsoNormal> <o:p>&nbsp;</o:p>
  <p class=MsoNormal>&nbsp;
  <p class=MsoNormal>&nbsp;
  <p class=MsoNormal>&nbsp;
  <div align="center"><strong>EE 503 Statistical Signal Processing and Modeling
    </strong><br>
    <strong>(Fall 2019&ndash; 2020)</strong></div>
  </p>

<table align=center width=75% border="0">
    <tr>
      <td><p class="style1"><strong>Short Description: </strong></p>
        <p class="style1"> This course is the first course on statistical signal
          processing in the graduate curriculum of Department of Electrical and
          Electronics Engineering, Middle East Technical University (METU). Topics
          covered in this course are random vectors, random processes, stationary
          random processes, wide sense stationary processes and their processing
          with LTI systems with applications in optimal filtering, smoothing and
          prediction. A major goal is to introduce the concept of mean square
          error (MSE) optimal processing of random signals by LTI systems. <br>
          <br>
          For the processing of the random signals, it is assumed that some statistical
          information about the signal of interest and distortion is known. By
          utilizing this information, MSE optimal LTI filters (Wiener filters)
          are designed. This forms the processing part of the course. The estimation
          of the statistical information to construct Wiener filters forms the
          modeling part of the course. In the modeling part, we examine AR, MA,
          ARMA models for random signals and give a brief discussion of Pade,
          Prony methods for the deterministic modeling. Among other topics of
          importance are decorrelating transforms (whitening), spectral factorization,
          Karhunen-Loeve transform <br>
          <br>
          This course is a natural pre-requisite (not a formal one) to EE5506
          Advanced Statistical Signal Processing. The estimation theory topics
          in EE 503 is mostly limited to the moment description of random processes
          which forms a special, but the most important, case of EE 5506. </p>
        <p class="style1"><strong>Outline of Topics: </strong></p>
        <ol start="1" type="1" class="style1">
          <li>Review</li>
          <ol start="1" type="a">
            <li> Basics of Mathematical Deduction
              <ol>
                <li> Necessary, Sufficient Conditions</li>
                <li> Proofs via contradiction, contraposition</li>
              </ol>
            </li>
            <li>Basics of Linear Algebra
              <ol>
                <li>Linear independence of vectors (points in linear space)</li>
                <li>Range and Null space of the combination process</li>
                <li> Projection to Range/Null Space (orthogonality principle)
                </li>
                <li>Positive Definite Matrices</li>
              </ol>
            </li>
            <li>Basics of Probability
              <ol>
                <li> Probability as a mapping, axioms, conditional probability</li>
                <li>Expectation, law of large numbers</li>
                <li>Moments, moment generating function</li>
              </ol>
            </li>
          </ol>
          <br>
          <li>Random Processes
            <ol>
              <li>Random variables, random vectors (or a sequence of random variables),
                moment descriptions (mean, variance, correlation), decorrelating
                transforms</li>
              <li>Random processes, stationarity, wide Sense Stationarity (WSS),
                power spectral density, spectral factorization, linear time invariant
                processing of WSS random processes, ergodicity </li>
            </ol>
            <br>
            Ref: Therrien, Hayes, Papoulis, Ross<br>&nbsp
			</li>
          <li>Signal Modeling
            <ol>
              <li>LS methods, Pade, Prony (Deterministic methods)</li>
              <li>AR, MA, ARMA Processes (Stochastic approach), Yule-Walker Equations,
                Non-linear set of equations for MA system fit</li>
              <li> Harmonic Processes </li>
            </ol>
            <br>
            Ref: Hayes, Papoulis <br>&nbsp
          <li>Estimation Theory Topics
            <ol>
              <li>Random parameter estimation
                <ol>
                  <li>Cost function, loss function, square error, absolute error</li>
                  <li> Conditional mean (regression line) as the minimum mean
                    square error (MSE) estimator, orthogonality properties</li>
                  <li> Linear minimum mean square error (LMMSE) estimators, orthogonality
                    principle </li>
                  <li>Regression line, orthogonality </li>
                  <li>FIR, IIR, Causal–IIR Wiener filters</li>
                  <li>Linear Prediction, backward prediction</li>
                  <li>Random vector LMMSE estimation (multiple parameter)</li>
                </ol>
              </li>
              <li>Non-random parameter estimation
                <ol>
                  <li>Maximum likelihood method</li>
                  <li> Best Linear Unbiased Estimator (BLUE)</li>
                  <li>Discussion of linear estimators for the linear observation
                    model y=Ax+n</li>
                </ol>
              </li>
              <li>Karhunen – Loeve Transform</li>
            </ol>
            <br>
            Ref: Therrien, Hayes<br>&nbsp
        </ol>
        </li>
        <strong>References: </strong><br>
        <p class="style1">[Hayes]: M. H. Hayes, Statistical Signal Processing and Modeling, Wiley,
        New York, NY, 1996.</p>
        <p class="style1">[Therrien]: C. W. Therrien, Discrete random signals
          and statistical signal processing, Prentice Hall, c1992.</p>
        <p class="style1">[Papoulis]: A. Papoulis, Probability, Random Variables,
          and Stochastic Processes, 3rd edition, McGraw Hill, 1991. </p>
        <p class="style1">[Ross]: S. M. Ross, Introduction to probability models,
          7th ed. Harcourt Academic Press, 2000.</p>
        </td>
  </tr>
</table>

</div>
</body>

</html>
